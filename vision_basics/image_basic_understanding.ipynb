{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data Fundamentals\n",
    "\n",
    "## Definition of Digital Images\n",
    "\n",
    "A digital image is a numerical representation of visual information, discretized into a grid of picture elements (pixels). Mathematically, an image $I$ can be represented as a function:\n",
    "\n",
    "$$I: \\Omega \\subset \\mathbb{R}^2 \\rightarrow \\mathbb{R}^c$$\n",
    "\n",
    "Where $\\Omega$ represents the spatial domain and $c$ denotes the number of channels.\n",
    "\n",
    "## Digital Image Properties\n",
    "\n",
    "### Width and Height\n",
    "\n",
    "The width ($W$) and height ($H$) of an image define its spatial dimensions in pixels. An image can be represented as a matrix:\n",
    "\n",
    "$$I = \\begin{bmatrix}\n",
    "p_{1,1} & p_{1,2} & \\cdots & p_{1,W} \\\\\n",
    "p_{2,1} & p_{2,2} & \\cdots & p_{2,W} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "p_{H,1} & p_{H,2} & \\cdots & p_{H,W}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Where $p_{i,j}$ represents the pixel value at coordinates $(i,j)$.\n",
    "\n",
    "### Channels\n",
    "\n",
    "Channels represent different color or intensity components of an image. For an RGB image with 3 channels:\n",
    "\n",
    "$$I_{RGB} = \\{I_R, I_G, I_B\\}$$\n",
    "\n",
    "Where each channel $I_c$ is a matrix with dimensions $H \\times W$.\n",
    "\n",
    "The tensor representation of a color image:\n",
    "\n",
    "$$I \\in \\mathbb{R}^{H \\times W \\times C}$$\n",
    "\n",
    "## Computer Understanding of Images\n",
    "\n",
    "Computers interpret images as numerical arrays. Each pixel value is quantized into discrete intensity levels:\n",
    "\n",
    "$$p_{i,j,c} \\in [0, 2^b-1]$$\n",
    "\n",
    "Where $b$ is the bit depth (typically 8 bits per channel, giving values from 0-255).\n",
    "![](./images/12.webp)\n",
    "### Memory Representation\n",
    "\n",
    "Images in memory follow a layout defined by:\n",
    "\n",
    "$$\\text{Address}(x,y,c) = \\text{Base} + (y \\cdot W + x) \\cdot C + c$$\n",
    "\n",
    "For row-major storage, where $\\text{Base}$ is the starting memory address.\n",
    "\n",
    "## Channel Significance\n",
    "\n",
    "### RGB Color Model\n",
    "\n",
    "RGB channels represent the additive color model expressed as:\n",
    "\n",
    "$$I_{RGB}(x,y) = [r(x,y), g(x,y), b(x,y)]$$\n",
    "\n",
    "Where intensity values typically range from 0 to 255 for 8-bit encoding.\n",
    "\n",
    "### Grayscale\n",
    "\n",
    "Single-channel representation where intensity is calculated as:\n",
    "\n",
    "$$I_{gray}(x,y) = 0.299 \\cdot r(x,y) + 0.587 \\cdot g(x,y) + 0.114 \\cdot b(x,y)$$\n",
    "\n",
    "### Alpha Channel\n",
    "\n",
    "Represents transparency where:\n",
    "\n",
    "$$I_{RGBA}(x,y) = [r(x,y), g(x,y), b(x,y), \\alpha(x,y)]$$\n",
    "\n",
    "$\\alpha = 0$ indicates full transparency; $\\alpha = 255$ indicates full opacity.\n",
    "\n",
    "### Domain-Specific Channels\n",
    "\n",
    "- **Medical Imaging**: DICOM images often use 16-bit single channel for radiographic data\n",
    "- **Multispectral Imaging**: Multiple discrete channels representing specific electromagnetic wavelengths\n",
    "- **Thermal Imaging**: Single channel representing temperature gradients\n",
    "\n",
    "## Height and Width Significance\n",
    "\n",
    "### Resolution Considerations\n",
    "\n",
    "The total number of pixels in an image is defined by:\n",
    "\n",
    "$$\\text{Resolution} = W \\times H$$\n",
    "\n",
    "Higher resolution increases detail but requires more storage and processing resources.\n",
    "\n",
    "### Aspect Ratio\n",
    "\n",
    "The relationship between width and height:\n",
    "\n",
    "$$\\text{Aspect Ratio} = \\frac{W}{H}$$\n",
    "\n",
    "Common aspect ratios: 16:9 (widescreen), 4:3 (standard), 1:1 (square).\n",
    "\n",
    "## Optimal Dimension Selection\n",
    "\n",
    "### Network Architecture Constraints\n",
    "\n",
    "Many deep learning models require fixed input dimensions:\n",
    "\n",
    "- **ResNet**: 224×224 pixels\n",
    "- **YOLO**: 416×416 or 608×608 pixels\n",
    "- **EfficientNet**: Dynamic sizing based on scaling coefficients\n",
    "\n",
    "### Application-Specific Considerations\n",
    "\n",
    "#### Medical Imaging\n",
    "\n",
    "- **CT/MRI**: High-resolution isotropic voxels (e.g., 512×512×Z)\n",
    "- **Histopathology**: Ultra-high resolution (10,000×10,000+ pixels)\n",
    "- **Optimal dimensions**: Preserve clinical features at minimum necessary resolution\n",
    "\n",
    "#### Real-time Vision Systems\n",
    "\n",
    "Dimensions balanced by the equation:\n",
    "\n",
    "$$\\text{Processing Time} \\propto W \\times H \\times C \\times \\text{Computational Complexity}$$\n",
    "\n",
    "Common resolutions:\n",
    "- **High-speed tracking**: 320×240 (QVGA)\n",
    "- **Autonomous vehicles**: 1280×720 (720p)\n",
    "- **Industrial inspection**: Application-specific, balancing detail and speed\n",
    "\n",
    "#### Camera Systems\n",
    "\n",
    "Resolution determined by sensor dimensions and pixel density:\n",
    "\n",
    "$$\\text{Resolution} = \\text{Sensor Width} \\times \\text{Sensor Height} \\times \\text{Pixel Density}^2$$\n",
    "\n",
    "## Image File Formats\n",
    "\n",
    "### Lossless Formats\n",
    "\n",
    "- **PNG**: Supports transparency, uses DEFLATE compression\n",
    "- **TIFF**: Versatile, supports multiple compression algorithms\n",
    "- **BMP**: Simple format with minimal or no compression\n",
    "\n",
    "### Lossy Formats\n",
    "\n",
    "- **JPEG**: Uses discrete cosine transform (DCT) compression\n",
    "- **WebP**: Modern format with superior compression ratios\n",
    "\n",
    "### Special-Purpose Formats\n",
    "\n",
    "- **DICOM**: Medical imaging standard with metadata\n",
    "- **FITS**: Astronomical imaging\n",
    "- **RAW**: Camera-specific formats preserving sensor data\n",
    "\n",
    "### Format Selection Criteria\n",
    "\n",
    "Format selection depends on the optimization metric:\n",
    "- **Size-constrained**: Choose lossy compression\n",
    "- **Quality-critical**: Choose lossless formats\n",
    "- **Application-specific**: Choose domain-specialized formats\n",
    "- **Compatibility**: Choose widely-supported formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Transformations in Computer Vision\n",
    "\n",
    "## 1. Rotation\n",
    "\n",
    "### Definition\n",
    "Rotation is a geometric transformation that turns an image around a pivot point by a specified angle $\\theta$.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For a point $(x, y)$ in the original image, its rotated coordinates $(x', y')$ around the origin $(0, 0)$ by angle $\\theta$ are:\n",
    "\n",
    "$$x' = x\\cos(\\theta) - y\\sin(\\theta)$$\n",
    "$$y' = x\\sin(\\theta) + y\\cos(\\theta)$$\n",
    "\n",
    "For rotation around a center point $(c_x, c_y)$ (typically the image center):\n",
    "\n",
    "$$x' = (x-c_x)\\cos(\\theta) - (y-c_y)\\sin(\\theta) + c_x$$\n",
    "$$y' = (x-c_x)\\sin(\\theta) + (y-c_y)\\cos(\\theta) + c_y$$\n",
    "\n",
    "### Matrix Representation\n",
    "Rotation around the origin can be expressed as:\n",
    "\n",
    "$$\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\ \\sin(\\theta) & \\cos(\\theta) \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}$$\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "When rotating a tensor with dimensions (channels, height, width):\n",
    "\n",
    "```\n",
    "function rotate_image(image, angle, center=None):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    if center is None:\n",
    "        center = (w/2, h/2)\n",
    "    \n",
    "    # Convert angle to radians\n",
    "    theta = angle * PI / 180\n",
    "    cos_theta, sin_theta = cos(theta), sin(theta)\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_h = int(abs(h * cos_theta) + abs(w * sin_theta))\n",
    "    new_w = int(abs(w * cos_theta) + abs(h * sin_theta))\n",
    "    \n",
    "    # Create output tensor\n",
    "    output = zeros((c, new_h, new_w))\n",
    "    \n",
    "    # Inverse mapping\n",
    "    for y_out in range(new_h):\n",
    "        for x_out in range(new_w):\n",
    "            # Centered coordinates\n",
    "            x = x_out - new_w/2\n",
    "            y = y_out - new_h/2\n",
    "            \n",
    "            # Apply inverse rotation\n",
    "            x_orig = x * cos_theta + y * sin_theta + w/2\n",
    "            y_orig = -x * sin_theta + y * cos_theta + h/2\n",
    "            \n",
    "            # If within bounds, copy pixel (with interpolation)\n",
    "            if 0 <= x_orig < w and 0 <= y_orig < h:\n",
    "                for ch in range(c):\n",
    "                    output[ch, y_out, x_out] = interpolate(image[ch], x_orig, y_orig)\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "## 2. Flipping\n",
    "\n",
    "### Definition\n",
    "Flipping mirrors an image across either the horizontal or vertical axis.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For horizontal flipping of an image with width $w$:\n",
    "$$x' = w - 1 - x$$\n",
    "$$y' = y$$\n",
    "\n",
    "For vertical flipping of an image with height $h$:\n",
    "$$x' = x$$\n",
    "$$y' = h - 1 - y$$\n",
    "\n",
    "### Matrix Representation\n",
    "For horizontal flipping:\n",
    "$$\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = \\begin{bmatrix} -1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} + \\begin{bmatrix} w-1 \\\\ 0 \\end{bmatrix}$$\n",
    "\n",
    "For vertical flipping:\n",
    "$$\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ h-1 \\end{bmatrix}$$\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function flip_image(image, direction):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = zeros_like(image)\n",
    "    \n",
    "    if direction == \"horizontal\":\n",
    "        for ch in range(c):\n",
    "            for y in range(h):\n",
    "                for x in range(w):\n",
    "                    output[ch, y, x] = image[ch, y, w-1-x]\n",
    "    \n",
    "    elif direction == \"vertical\":\n",
    "        for ch in range(c):\n",
    "            for y in range(h):\n",
    "                for x in range(w):\n",
    "                    output[ch, y, x] = image[ch, h-1-y, x]\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "Efficient implementation:\n",
    "```\n",
    "function flip_image(image, direction):\n",
    "    if direction == \"horizontal\":\n",
    "        return image[:, :, ::-1]  # Reverse width dimension\n",
    "    elif direction == \"vertical\":\n",
    "        return image[:, ::-1, :]  # Reverse height dimension\n",
    "```\n",
    "\n",
    "## 3. Scaling\n",
    "\n",
    "### Definition\n",
    "Scaling resizes an image by multiplying its dimensions by scale factors.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For scaling by factors $s_x$ and $s_y$:\n",
    "$$x' = x \\cdot s_x$$\n",
    "$$y' = y \\cdot s_y$$\n",
    "\n",
    "### Matrix Representation\n",
    "$$\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = \\begin{bmatrix} s_x & 0 \\\\ 0 & s_y \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}$$\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function scale_image(image, scale_x, scale_y):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_h, new_w = int(h * scale_y), int(w * scale_x)\n",
    "    \n",
    "    # Create output tensor\n",
    "    output = zeros((c, new_h, new_w))\n",
    "    \n",
    "    # Inverse mapping\n",
    "    for y_out in range(new_h):\n",
    "        for x_out in range(new_w):\n",
    "            # Find source position\n",
    "            x_orig = x_out / scale_x\n",
    "            y_orig = y_out / scale_y\n",
    "            \n",
    "            # Apply interpolation\n",
    "            for ch in range(c):\n",
    "                output[ch, y_out, x_out] = bilinear_interpolate(\n",
    "                    image[ch], x_orig, y_orig)\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "### Interpolation Methods\n",
    "- **Nearest Neighbor**: Uses value of closest pixel\n",
    "- **Bilinear**: Weighted average of 4 nearest pixels\n",
    "- **Bicubic**: Weighted average of 16 nearest pixels\n",
    "\n",
    "## 4. Translation\n",
    "\n",
    "### Definition\n",
    "Translation shifts an image by a constant offset in x and/or y directions.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For translation by $(t_x, t_y)$:\n",
    "$$x' = x + t_x$$\n",
    "$$y' = y + t_y$$\n",
    "\n",
    "### Matrix Representation (Homogeneous Coordinates)\n",
    "$$\\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 & t_x \\\\ 0 & 1 & t_y \\\\ 0 & 0 & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function translate_image(image, tx, ty, fill_value=0):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    \n",
    "    # Create output tensor\n",
    "    output = full((c, h, w), fill_value)\n",
    "    \n",
    "    # Copy pixels with offset\n",
    "    for y_out in range(h):\n",
    "        y_in = y_out - ty\n",
    "        if 0 <= y_in < h:\n",
    "            for x_out in range(w):\n",
    "                x_in = x_out - tx\n",
    "                if 0 <= x_in < w:\n",
    "                    for ch in range(c):\n",
    "                        output[ch, y_out, x_out] = image[ch, y_in, x_in]\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "## 5. Cropping\n",
    "\n",
    "### Definition\n",
    "Cropping extracts a rectangular region from an image.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For cropping a region starting at $(x_0, y_0)$ with width $w'$ and height $h'$:\n",
    "The new image consists of pixels $(x, y)$ where:\n",
    "$$x_0 \\leq x < x_0 + w'$$\n",
    "$$y_0 \\leq y < y_0 + h'$$\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function crop_image(image, x0, y0, crop_width, crop_height):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    \n",
    "    # Ensure crop region is within bounds\n",
    "    x0 = max(0, min(x0, w-1))\n",
    "    y0 = max(0, min(y0, h-1))\n",
    "    crop_width = min(crop_width, w - x0)\n",
    "    crop_height = min(crop_height, h - y0)\n",
    "    \n",
    "    # Extract region\n",
    "    output = zeros((c, crop_height, crop_width))\n",
    "    \n",
    "    for ch in range(c):\n",
    "        for y in range(crop_height):\n",
    "            for x in range(crop_width):\n",
    "                output[ch, y, x] = image[ch, y0 + y, x0 + x]\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "Efficient implementation:\n",
    "```\n",
    "function crop_image(image, x0, y0, crop_width, crop_height):\n",
    "    # Ensure crop region is within bounds\n",
    "    c, h, w = image.shape\n",
    "    x0 = max(0, min(x0, w-1))\n",
    "    y0 = max(0, min(y0, h-1))\n",
    "    x1 = min(w, x0 + crop_width)\n",
    "    y1 = min(h, y0 + crop_height)\n",
    "    \n",
    "    # Extract region using slicing\n",
    "    return image[:, y0:y1, x0:x1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Transformations continue(day-2)...\n",
    "\n",
    "## 1. Brightness Adjustment\n",
    "\n",
    "### Definition\n",
    "Brightness adjustment modifies the luminance or intensity values of an image by adding a constant value to all pixels, effectively making the image appear brighter or darker.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For an image $I$ with pixel values in range $[0, 255]$ and brightness factor $\\beta$:\n",
    "\n",
    "$$I'(x,y,c) = \\text{clip}(I(x,y,c) + \\beta, 0, 255)$$\n",
    "\n",
    "Where:\n",
    "- $I(x,y,c)$ is the original pixel value at position $(x,y)$ for channel $c$\n",
    "- $I'(x,y,c)$ is the adjusted pixel value\n",
    "- $\\beta > 0$ increases brightness\n",
    "- $\\beta < 0$ decreases brightness\n",
    "- $\\text{clip}(v, min, max)$ constrains values to the valid range\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function adjust_brightness(image, beta):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = zeros_like(image)\n",
    "    \n",
    "    for ch in range(c):\n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                # Add brightness factor and clip to valid range\n",
    "                output[ch, y, x] = clip(image[ch, y, x] + beta, 0, 255)\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "### Vectorized Implementation\n",
    "\n",
    "```\n",
    "function adjust_brightness(image, beta):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    # Direct vectorized operation\n",
    "    return clip(image + beta, 0, 255)\n",
    "```\n",
    "\n",
    "## 2. Contrast Adjustment\n",
    "\n",
    "### Definition\n",
    "Contrast adjustment scales the difference between pixel values and a reference point (typically the mean intensity), enhancing or reducing the distinction between light and dark regions.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For contrast factor $\\alpha$:\n",
    "\n",
    "$$I'(x,y,c) = \\text{clip}(\\alpha \\times (I(x,y,c) - \\mu) + \\mu, 0, 255)$$\n",
    "\n",
    "Where:\n",
    "- $\\mu$ is the mean intensity of the image (often 128 for 8-bit images)\n",
    "- $\\alpha > 1$ increases contrast\n",
    "- $0 < \\alpha < 1$ decreases contrast\n",
    "- $\\alpha = 1$ leaves contrast unchanged\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function adjust_contrast(image, alpha, mean_value=128):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = zeros_like(image)\n",
    "    \n",
    "    for ch in range(c):\n",
    "        # Option 1: Use global mean value (typically 128 for 8-bit images)\n",
    "        # Option 2: Calculate mean of the channel\n",
    "        # channel_mean = sum(image[ch]) / (h * w)\n",
    "        \n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                # Apply contrast formula and clip\n",
    "                output[ch, y, x] = clip(\n",
    "                    alpha * (image[ch, y, x] - mean_value) + mean_value, \n",
    "                    0, 255)\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "### Vectorized Implementation\n",
    "\n",
    "```\n",
    "function adjust_contrast(image, alpha, mean_value=128):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    return clip(alpha * (image - mean_value) + mean_value, 0, 255)\n",
    "```\n",
    "\n",
    "## 3. Saturation Adjustment\n",
    "\n",
    "### Definition\n",
    "Saturation adjustment modifies the intensity of colors in an image without changing its luminance, making colors appear more vibrant or muted.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For RGB images, saturation adjustment requires conversion to HSV color space, adjustment of the S channel, and conversion back to RGB:\n",
    "\n",
    "1. Convert RGB to HSV:\n",
    "   $$V = \\max(R, G, B)$$\n",
    "   $$S = \\begin{cases}\n",
    "   \\frac{V - \\min(R,G,B)}{V}, & \\text{if } V \\neq 0 \\\\\n",
    "   0, & \\text{otherwise}\n",
    "   \\end{cases}$$\n",
    "   $$H = \\begin{cases}\n",
    "   60 \\times \\frac{G-B}{V-\\min(R,G,B)} \\mod 360, & \\text{if } V = R \\\\\n",
    "   60 \\times \\frac{B-R}{V-\\min(R,G,B)} + 120, & \\text{if } V = G \\\\\n",
    "   60 \\times \\frac{R-G}{V-\\min(R,G,B)} + 240, & \\text{if } V = B\n",
    "   \\end{cases}$$\n",
    "\n",
    "2. Modify saturation:\n",
    "   $$S' = \\text{clip}(S \\times \\gamma, 0, 1)$$\n",
    "   Where $\\gamma$ is the saturation factor\n",
    "\n",
    "3. Convert back to RGB (simplified):\n",
    "   $$C = V \\times S'$$\n",
    "   $$X = C \\times (1 - |((H / 60) \\mod 2) - 1|)$$\n",
    "   $$m = V - C$$\n",
    "\n",
    "   $$(R', G', B') = \\begin{cases}\n",
    "   (C+m, X+m, m), & \\text{if } 0 \\leq H < 60 \\\\\n",
    "   (X+m, C+m, m), & \\text{if } 60 \\leq H < 120 \\\\\n",
    "   (m, C+m, X+m), & \\text{if } 120 \\leq H < 180 \\\\\n",
    "   (m, X+m, C+m), & \\text{if } 180 \\leq H < 240 \\\\\n",
    "   (X+m, m, C+m), & \\text{if } 240 \\leq H < 300 \\\\\n",
    "   (C+m, m, X+m), & \\text{if } 300 \\leq H < 360\n",
    "   \\end{cases}$$\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function adjust_saturation(image, gamma):\n",
    "    # image: tensor of shape (3, h, w) - RGB format\n",
    "    if image.shape[0] != 3:\n",
    "        raise ValueError(\"Saturation adjustment requires RGB image\")\n",
    "    \n",
    "    h, w = image.shape[1], image.shape[2]\n",
    "    output = zeros_like(image)\n",
    "    \n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            # Extract RGB values\n",
    "            r, g, b = image[0, y, x], image[1, y, x], image[2, y, x]\n",
    "            \n",
    "            # Convert to HSV\n",
    "            r, g, b = r/255.0, g/255.0, b/255.0  # Normalize to [0,1]\n",
    "            v = max(r, g, b)\n",
    "            min_val = min(r, g, b)\n",
    "            diff = v - min_val\n",
    "            \n",
    "            # Calculate saturation\n",
    "            s = diff/v if v != 0 else 0\n",
    "            \n",
    "            # Calculate hue\n",
    "            if diff == 0:\n",
    "                h_val = 0\n",
    "            elif v == r:\n",
    "                h_val = 60 * ((g - b)/diff % 6)\n",
    "            elif v == g:\n",
    "                h_val = 60 * ((b - r)/diff + 2)\n",
    "            else:  # v == b\n",
    "                h_val = 60 * ((r - g)/diff + 4)\n",
    "            \n",
    "            # Adjust saturation\n",
    "            s = clip(s * gamma, 0, 1)\n",
    "            \n",
    "            # Convert back to RGB\n",
    "            c = v * s\n",
    "            x = c * (1 - abs(((h_val/60) % 2) - 1))\n",
    "            m = v - c\n",
    "            \n",
    "            if 0 <= h_val < 60:\n",
    "                r_new, g_new, b_new = c+m, x+m, m\n",
    "            elif 60 <= h_val < 120:\n",
    "                r_new, g_new, b_new = x+m, c+m, m\n",
    "            elif 120 <= h_val < 180:\n",
    "                r_new, g_new, b_new = m, c+m, x+m\n",
    "            elif 180 <= h_val < 240:\n",
    "                r_new, g_new, b_new = m, x+m, c+m\n",
    "            elif 240 <= h_val < 300:\n",
    "                r_new, g_new, b_new = x+m, m, c+m\n",
    "            else:  # 300 <= h_val < 360\n",
    "                r_new, g_new, b_new = c+m, m, x+m\n",
    "            \n",
    "            # Convert back to [0,255] and store\n",
    "            output[0, y, x] = int(r_new * 255)\n",
    "            output[1, y, x] = int(g_new * 255)\n",
    "            output[2, y, x] = int(b_new * 255)\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "## 4. Gaussian Noise\n",
    "\n",
    "### Definition\n",
    "Gaussian noise adds random values to image pixels, where the values are drawn from a Gaussian (normal) distribution, simulating thermal noise in electronic systems.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For Gaussian noise with mean $\\mu$ and standard deviation $\\sigma$:\n",
    "\n",
    "$$I'(x,y,c) = \\text{clip}(I(x,y,c) + \\mathcal{N}(\\mu, \\sigma^2), 0, 255)$$\n",
    "\n",
    "Where:\n",
    "- $\\mathcal{N}(\\mu, \\sigma^2)$ represents a random value drawn from the normal distribution\n",
    "- $\\mu$ is typically 0 for zero-centered noise\n",
    "- $\\sigma$ controls the strength of the noise\n",
    "\n",
    "The probability density function (PDF) of the Gaussian distribution is:\n",
    "\n",
    "$$p(z) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(z-\\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function add_gaussian_noise(image, mean=0, sigma=15):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = zeros_like(image)\n",
    "    \n",
    "    for ch in range(c):\n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                # Generate random noise from Gaussian distribution\n",
    "                noise = random_normal(mean, sigma)\n",
    "                # Add noise and clip to valid range\n",
    "                output[ch, y, x] = clip(image[ch, y, x] + noise, 0, 255)\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "### Vectorized Implementation\n",
    "\n",
    "```\n",
    "function add_gaussian_noise(image, mean=0, sigma=15):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    \n",
    "    # Generate noise tensor of same shape as image\n",
    "    noise = random_normal(mean, sigma, size=(c, h, w))\n",
    "    \n",
    "    # Add noise and clip\n",
    "    return clip(image + noise, 0, 255)\n",
    "```\n",
    "\n",
    "## 5. Salt and Pepper Noise\n",
    "\n",
    "### Definition\n",
    "Salt and pepper noise (also known as impulse noise) randomly replaces pixels with either minimum (pepper) or maximum (salt) values, simulating defects in image sensors or transmission errors.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For salt and pepper noise with probability $p$:\n",
    "\n",
    "$$I'(x,y,c) = \\begin{cases}\n",
    "0 \\text{ (pepper)}, & \\text{with probability } \\frac{p}{2} \\\\\n",
    "255 \\text{ (salt)}, & \\text{with probability } \\frac{p}{2} \\\\\n",
    "I(x,y,c), & \\text{with probability } 1-p\n",
    "\\end{cases}$$\n",
    "\n",
    "Where:\n",
    "- $p$ is the total probability of a pixel being affected (typically 0.01 to 0.1)\n",
    "- Half of affected pixels become 'salt' (255)\n",
    "- Half of affected pixels become 'pepper' (0)\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function add_salt_pepper_noise(image, prob=0.05):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = copy(image)\n",
    "    \n",
    "    # Total number of pixels\n",
    "    total_pixels = c * h * w\n",
    "    \n",
    "    # Number of salt and pepper pixels\n",
    "    num_salt = int((prob/2) * total_pixels)\n",
    "    num_pepper = int((prob/2) * total_pixels)\n",
    "    \n",
    "    # Add salt noise (white pixels)\n",
    "    for _ in range(num_salt):\n",
    "        # Random channel, y and x coordinates\n",
    "        ch = random_int(0, c-1)\n",
    "        y = random_int(0, h-1)\n",
    "        x = random_int(0, w-1)\n",
    "        output[ch, y, x] = 255\n",
    "    \n",
    "    # Add pepper noise (black pixels)\n",
    "    for _ in range(num_pepper):\n",
    "        # Random channel, y and x coordinates\n",
    "        ch = random_int(0, c-1)\n",
    "        y = random_int(0, h-1)\n",
    "        x = random_int(0, w-1)\n",
    "        output[ch, y, x] = 0\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "### Alternative Implementation with Random Mask\n",
    "\n",
    "```\n",
    "function add_salt_pepper_noise(image, prob=0.05):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = copy(image)\n",
    "    \n",
    "    # Generate random values for all pixels\n",
    "    rnd = random_uniform(size=(c, h, w))\n",
    "    \n",
    "    # Salt mask (where pixel values should be 255)\n",
    "    salt_mask = rnd < prob/2\n",
    "    # Pepper mask (where pixel values should be 0)\n",
    "    pepper_mask = (rnd >= prob/2) & (rnd < prob)\n",
    "    \n",
    "    # Apply salt (white) and pepper (black) noise\n",
    "    output[salt_mask] = 255\n",
    "    output[pepper_mask] = 0\n",
    "    \n",
    "    return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing and Augmentation Techniques continue(day3)...\n",
    "\n",
    "## 1. Gaussian Blur\n",
    "\n",
    "### Definition\n",
    "Gaussian blur is a linear low-pass filter that convolves an image with a Gaussian function to reduce noise and detail by applying a weighted average of pixel values in a local neighborhood.\n",
    "\n",
    "### Mathematical Formulation\n",
    "The 2D Gaussian function is defined as:\n",
    "\n",
    "$$G(x,y) = \\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}$$\n",
    "\n",
    "Where:\n",
    "- $(x,y)$ is the distance from the origin\n",
    "- $\\sigma$ is the standard deviation controlling blur strength\n",
    "\n",
    "For discrete images, we create a kernel of size $(2k+1) \\times (2k+1)$ where $k \\approx 3\\sigma$.\n",
    "\n",
    "The blurred image is obtained through convolution:\n",
    "\n",
    "$$I'(x,y) = I(x,y) * G(x,y) = \\sum_{i=-k}^{k}\\sum_{j=-k}^{k} G(i,j) \\cdot I(x-i, y-j)$$\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function gaussian_blur(image, kernel_size, sigma):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = zeros_like(image)\n",
    "    \n",
    "    # Create Gaussian kernel\n",
    "    k = kernel_size // 2\n",
    "    kernel = zeros((kernel_size, kernel_size))\n",
    "    \n",
    "    # Fill kernel with Gaussian values\n",
    "    for i in range(-k, k+1):\n",
    "        for j in range(-k, k+1):\n",
    "            kernel[i+k, j+k] = (1/(2*pi*sigma**2)) * exp(-(i**2 + j**2)/(2*sigma**2))\n",
    "    \n",
    "    # Normalize kernel\n",
    "    kernel = kernel / kernel.sum()\n",
    "    \n",
    "    # Apply convolution with padding\n",
    "    padded = pad(image, ((0,0), (k,k), (k,k)), mode='reflect')\n",
    "    \n",
    "    for ch in range(c):\n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                # Apply kernel\n",
    "                for i in range(kernel_size):\n",
    "                    for j in range(kernel_size):\n",
    "                        output[ch, y, x] += kernel[i, j] * padded[ch, y+i, x+j]\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "### Separable Implementation (Optimized)\n",
    "\n",
    "```\n",
    "function gaussian_blur_separable(image, kernel_size, sigma):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    \n",
    "    # Create 1D Gaussian kernel\n",
    "    k = kernel_size // 2\n",
    "    kernel_1d = zeros(kernel_size)\n",
    "    \n",
    "    for i in range(-k, k+1):\n",
    "        kernel_1d[i+k] = (1/(sqrt(2*pi)*sigma)) * exp(-(i**2)/(2*sigma**2))\n",
    "    \n",
    "    # Normalize kernel\n",
    "    kernel_1d = kernel_1d / kernel_1d.sum()\n",
    "    \n",
    "    # Apply horizontal blur\n",
    "    temp = zeros_like(image)\n",
    "    padded_h = pad(image, ((0,0), (0,0), (k,k)), mode='reflect')\n",
    "    \n",
    "    for ch in range(c):\n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                for j in range(kernel_size):\n",
    "                    temp[ch, y, x] += kernel_1d[j] * padded_h[ch, y, x+j]\n",
    "    \n",
    "    # Apply vertical blur\n",
    "    output = zeros_like(image)\n",
    "    padded_v = pad(temp, ((0,0), (k,k), (0,0)), mode='reflect')\n",
    "    \n",
    "    for ch in range(c):\n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                for i in range(kernel_size):\n",
    "                    output[ch, y, x] += kernel_1d[i] * padded_v[ch, y+i, x]\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "## 2. Sharpening\n",
    "\n",
    "### Definition\n",
    "Sharpening enhances edges and details in an image by amplifying high-frequency components, typically achieved by adding a scaled version of the image's Laplacian to the original image.\n",
    "\n",
    "### Mathematical Formulation\n",
    "The unsharp masking algorithm is defined as:\n",
    "\n",
    "$$I'(x,y) = I(x,y) + \\lambda \\cdot L(x,y)$$\n",
    "\n",
    "Where:\n",
    "- $I(x,y)$ is the original image\n",
    "- $L(x,y)$ is the Laplacian of the image\n",
    "- $\\lambda$ is a scaling factor controlling sharpening strength\n",
    "\n",
    "The Laplacian kernel is typically:\n",
    "\n",
    "$$L = \\begin{bmatrix} 0 & -1 & 0 \\\\ -1 & 4 & -1 \\\\ 0 & -1 & 0 \\end{bmatrix}$$\n",
    "\n",
    "Or for 8-connectivity:\n",
    "\n",
    "$$L = \\begin{bmatrix} -1 & -1 & -1 \\\\ -1 & 8 & -1 \\\\ -1 & -1 & -1 \\end{bmatrix}$$\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function sharpen_image(image, strength=1.0):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = zeros_like(image)\n",
    "    \n",
    "    # Laplacian kernel\n",
    "    laplacian_kernel = array([\n",
    "        [0, -1, 0],\n",
    "        [-1, 4, -1],\n",
    "        [0, -1, 0]\n",
    "    ])\n",
    "    \n",
    "    # Apply convolution with padding\n",
    "    padded = pad(image, ((0,0), (1,1), (1,1)), mode='reflect')\n",
    "    \n",
    "    for ch in range(c):\n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                # Compute Laplacian\n",
    "                laplacian = 0\n",
    "                for i in range(3):\n",
    "                    for j in range(3):\n",
    "                        laplacian += laplacian_kernel[i, j] * padded[ch, y+i, x+j]\n",
    "                \n",
    "                # Apply sharpening\n",
    "                output[ch, y, x] = clip(image[ch, y, x] + strength * laplacian, 0, 255)\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "### Single-Pass Implementation with Combined Kernel\n",
    "\n",
    "```\n",
    "function sharpen_image_single_pass(image, strength=1.0):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = zeros_like(image)\n",
    "    \n",
    "    # Combined sharpening kernel\n",
    "    center_value = 4 * strength + 1\n",
    "    sharpening_kernel = array([\n",
    "        [0, -strength, 0],\n",
    "        [-strength, center_value, -strength],\n",
    "        [0, -strength, 0]\n",
    "    ])\n",
    "    \n",
    "    # Apply convolution with padding\n",
    "    padded = pad(image, ((0,0), (1,1), (1,1)), mode='reflect')\n",
    "    \n",
    "    for ch in range(c):\n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                # Apply kernel\n",
    "                pixel_value = 0\n",
    "                for i in range(3):\n",
    "                    for j in range(3):\n",
    "                        pixel_value += sharpening_kernel[i, j] * padded[ch, y+i, x+j]\n",
    "                \n",
    "                output[ch, y, x] = clip(pixel_value, 0, 255)\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "## 3. Affine Transformations\n",
    "\n",
    "### Definition\n",
    "Affine transformations preserve collinearity and parallelism of lines while allowing translation, rotation, scaling, and shearing operations in a combined linear manner.\n",
    "\n",
    "### Mathematical Formulation\n",
    "An affine transformation can be represented in matrix form:\n",
    "\n",
    "$$\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} + \\begin{bmatrix} t_x \\\\ t_y \\end{bmatrix}$$\n",
    "\n",
    "Using homogeneous coordinates:\n",
    "\n",
    "$$\\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} a & b & t_x \\\\ c & d & t_y \\\\ 0 & 0 & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "Key affine transformation matrices:\n",
    "\n",
    "1. Translation by $(t_x, t_y)$:\n",
    "   $$T = \\begin{bmatrix} 1 & 0 & t_x \\\\ 0 & 1 & t_y \\\\ 0 & 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "2. Rotation by angle $\\theta$:\n",
    "   $$R = \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta) & 0 \\\\ \\sin(\\theta) & \\cos(\\theta) & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "3. Scaling by factors $(s_x, s_y)$:\n",
    "   $$S = \\begin{bmatrix} s_x & 0 & 0 \\\\ 0 & s_y & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "4. Shearing by factors $(s_h^x, s_h^y)$:\n",
    "   $$H = \\begin{bmatrix} 1 & s_h^x & 0 \\\\ s_h^y & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function affine_transform(image, matrix, output_shape=None):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    \n",
    "    if output_shape is None:\n",
    "        output_shape = (h, w)\n",
    "    \n",
    "    output_h, output_w = output_shape\n",
    "    output = zeros((c, output_h, output_w))\n",
    "    \n",
    "    # Inverse mapping\n",
    "    inv_matrix = inverse(matrix)\n",
    "    \n",
    "    for y_out in range(output_h):\n",
    "        for x_out in range(output_w):\n",
    "            # Convert to homogeneous coordinates\n",
    "            p_out = array([x_out, y_out, 1])\n",
    "            \n",
    "            # Apply inverse transform to find source pixel\n",
    "            p_in = inv_matrix @ p_out\n",
    "            \n",
    "            # Convert back from homogeneous coordinates\n",
    "            x_in, y_in = p_in[0] / p_in[2], p_in[1] / p_in[2]\n",
    "            \n",
    "            # Check if source pixel is within bounds\n",
    "            if 0 <= x_in < w-1 and 0 <= y_in < h-1:\n",
    "                # Bilinear interpolation\n",
    "                x0, y0 = int(x_in), int(y_in)\n",
    "                x1, y1 = x0 + 1, y0 + 1\n",
    "                \n",
    "                dx = x_in - x0\n",
    "                dy = y_in - y0\n",
    "                \n",
    "                for ch in range(c):\n",
    "                    # Interpolate\n",
    "                    val = (1-dx)*(1-dy)*image[ch, y0, x0] + \\\n",
    "                          dx*(1-dy)*image[ch, y0, x1] + \\\n",
    "                          (1-dx)*dy*image[ch, y1, x0] + \\\n",
    "                          dx*dy*image[ch, y1, x1]\n",
    "                    \n",
    "                    output[ch, y_out, x_out] = val\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "### Matrix Creation Function\n",
    "\n",
    "```\n",
    "function create_affine_matrix(rotation=0, scale=(1, 1), translation=(0, 0), shear=(0, 0)):\n",
    "    # Convert rotation to radians\n",
    "    theta = rotation * pi / 180\n",
    "    \n",
    "    # Create rotation matrix\n",
    "    rot_matrix = array([\n",
    "        [cos(theta), -sin(theta), 0],\n",
    "        [sin(theta), cos(theta), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # Create scaling matrix\n",
    "    scale_matrix = array([\n",
    "        [scale[0], 0, 0],\n",
    "        [0, scale[1], 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # Create shear matrix\n",
    "    shear_matrix = array([\n",
    "        [1, shear[0], 0],\n",
    "        [shear[1], 1, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # Create translation matrix\n",
    "    trans_matrix = array([\n",
    "        [1, 0, translation[0]],\n",
    "        [0, 1, translation[1]],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # Combine all transformations (order matters)\n",
    "    # First scale, then shear, then rotate, finally translate\n",
    "    return trans_matrix @ rot_matrix @ shear_matrix @ scale_matrix\n",
    "```\n",
    "\n",
    "## 4. Elastic Deformations\n",
    "\n",
    "### Definition\n",
    "Elastic deformation simulates random local distortions in an image by applying a dense displacement field, creating realistic variations while preserving the underlying structure.\n",
    "\n",
    "### Mathematical Formulation\n",
    "The process involves:\n",
    "\n",
    "1. Generate random displacement fields $\\Delta x(x,y)$ and $\\Delta y(x,y)$\n",
    "2. Smooth these fields using a Gaussian filter with standard deviation $\\sigma$\n",
    "3. Scale the displacement fields by factor $\\alpha$\n",
    "4. Compute new pixel coordinates:\n",
    "   $$x' = x + \\alpha \\cdot \\Delta x(x,y)$$\n",
    "   $$y' = y + \\alpha \\cdot \\Delta y(x,y)$$\n",
    "\n",
    "The probability density function of the Gaussian filter is:\n",
    "\n",
    "$$G(x,y) = \\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}$$\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function elastic_deformation(image, alpha=10, sigma=4):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = zeros_like(image)\n",
    "    \n",
    "    # Generate random displacement fields\n",
    "    dx = random_uniform(-1, 1, size=(h, w))\n",
    "    dy = random_uniform(-1, 1, size=(h, w))\n",
    "    \n",
    "    # Smooth displacement fields using Gaussian filter\n",
    "    dx = gaussian_filter(dx, sigma=sigma)\n",
    "    dy = gaussian_filter(dy, sigma=sigma)\n",
    "    \n",
    "    # Scale displacement fields\n",
    "    dx = dx * alpha\n",
    "    dy = dy * alpha\n",
    "    \n",
    "    # Create mesh grid of coordinates\n",
    "    y_indices, x_indices = meshgrid(range(h), range(w), indexing='ij')\n",
    "    \n",
    "    # Apply displacement fields\n",
    "    x_mapped = x_indices + dx\n",
    "    y_mapped = y_indices + dy\n",
    "    \n",
    "    # Clip to ensure indices are within image boundaries\n",
    "    x_mapped = clip(x_mapped, 0, w-1)\n",
    "    y_mapped = clip(y_mapped, 0, h-1)\n",
    "    \n",
    "    # Interpolate values for each channel\n",
    "    for ch in range(c):\n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                # Get source coordinates\n",
    "                x_src, y_src = x_mapped[y, x], y_mapped[y, x]\n",
    "                \n",
    "                # Bilinear interpolation\n",
    "                x0, y0 = int(x_src), int(y_src)\n",
    "                x1, y1 = min(x0 + 1, w-1), min(y0 + 1, h-1)\n",
    "                \n",
    "                dx_local = x_src - x0\n",
    "                dy_local = y_src - y0\n",
    "                \n",
    "                # Interpolate\n",
    "                val = (1-dx_local)*(1-dy_local)*image[ch, y0, x0] + \\\n",
    "                      dx_local*(1-dy_local)*image[ch, y0, x1] + \\\n",
    "                      (1-dx_local)*dy_local*image[ch, y1, x0] + \\\n",
    "                      dx_local*dy_local*image[ch, y1, x1]\n",
    "                \n",
    "                output[ch, y, x] = val\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "### Vectorized Implementation\n",
    "\n",
    "```\n",
    "function elastic_deformation_vectorized(image, alpha=10, sigma=4):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    \n",
    "    # Generate random displacement fields\n",
    "    dx = random_uniform(-1, 1, size=(h, w))\n",
    "    dy = random_uniform(-1, 1, size=(h, w))\n",
    "    \n",
    "    # Smooth displacement fields using Gaussian filter\n",
    "    dx = gaussian_filter(dx, sigma=sigma)\n",
    "    dy = gaussian_filter(dy, sigma=sigma)\n",
    "    \n",
    "    # Scale displacement fields\n",
    "    dx = dx * alpha\n",
    "    dy = dy * alpha\n",
    "    \n",
    "    # Create mesh grid of coordinates\n",
    "    y_indices, x_indices = meshgrid(range(h), range(w), indexing='ij')\n",
    "    \n",
    "    # Apply displacement fields\n",
    "    x_mapped = x_indices + dx\n",
    "    y_mapped = y_indices + dy\n",
    "    \n",
    "    # Clip to ensure indices are within image boundaries\n",
    "    x_mapped = clip(x_mapped, 0, w-1)\n",
    "    y_mapped = clip(y_mapped, 0, h-1)\n",
    "    \n",
    "    # Use map_coordinates for each channel\n",
    "    output = zeros_like(image)\n",
    "    for ch in range(c):\n",
    "        output[ch] = map_coordinates(image[ch], [y_mapped, x_mapped], order=1)\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "## 5. Random Erasing/Cutout\n",
    "\n",
    "### Definition\n",
    "Random Erasing (Cutout) is a data augmentation technique that randomly selects rectangular regions in an image and replaces them with constant values or noise, forcing the model to learn more robust features.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For an image $I$ and a randomly selected rectangular region $R(x_1:x_2, y_1:y_2)$:\n",
    "\n",
    "$$I'(x,y,c) = \\begin{cases} \n",
    "v, & \\text{if } (x,y) \\in R \\\\\n",
    "I(x,y,c), & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "Key parameters:\n",
    "- $p$: probability of applying erasing\n",
    "- $s_l, s_h$: min/max area ratio of erased rectangle\n",
    "- $r_1, r_2$: min/max aspect ratio of erased rectangle\n",
    "- $v$: replacement value (0, mean, or random)\n",
    "\n",
    "### Implementation for Image Tensor (C,H,W)\n",
    "\n",
    "```\n",
    "function random_erasing(image, p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=3.3, v=0):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = copy(image)\n",
    "    \n",
    "    # Apply random erasing with probability p\n",
    "    if random_uniform() > p:\n",
    "        return output\n",
    "    \n",
    "    # Get random area and aspect ratio\n",
    "    area = h * w\n",
    "    target_area = random_uniform(s_l, s_h) * area\n",
    "    aspect_ratio = random_uniform(r_1, r_2)\n",
    "    \n",
    "    # Calculate dimensions\n",
    "    h_cutout = int(sqrt(target_area * aspect_ratio))\n",
    "    w_cutout = int(sqrt(target_area / aspect_ratio))\n",
    "    \n",
    "    # Ensure cutout dimensions don't exceed image dimensions\n",
    "    h_cutout = min(h_cutout, h)\n",
    "    w_cutout = min(w_cutout, w)\n",
    "    \n",
    "    # Get random top-left corner\n",
    "    x0 = random_int(0, w - w_cutout)\n",
    "    y0 = random_int(0, h - h_cutout)\n",
    "    \n",
    "    # Fill the region with the specified value\n",
    "    if v == 'random':\n",
    "        for ch in range(c):\n",
    "            output[ch, y0:y0+h_cutout, x0:x0+w_cutout] = random_uniform(0, 255, size=(h_cutout, w_cutout))\n",
    "    elif v == 'mean':\n",
    "        for ch in range(c):\n",
    "            output[ch, y0:y0+h_cutout, x0:x0+w_cutout] = image[ch].mean()\n",
    "    else:  # Default: fill with zero or specified value\n",
    "        for ch in range(c):\n",
    "            output[ch, y0:y0+h_cutout, x0:x0+w_cutout] = v\n",
    "    \n",
    "    return output\n",
    "```\n",
    "\n",
    "### Vectorized Implementation\n",
    "\n",
    "```\n",
    "function random_erasing_vectorized(image, p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=3.3, v=0):\n",
    "    # image: tensor of shape (c, h, w)\n",
    "    c, h, w = image.shape\n",
    "    output = copy(image)\n",
    "    \n",
    "    # Apply random erasing with probability p\n",
    "    if random_uniform() > p:\n",
    "        return output\n",
    "    \n",
    "    # Get random area and aspect ratio\n",
    "    area = h * w\n",
    "    target_area = random_uniform(s_l, s_h) * area\n",
    "    aspect_ratio = random_uniform(r_1, r_2)\n",
    "    \n",
    "    # Calculate dimensions\n",
    "    h_cutout = int(sqrt(target_area * aspect_ratio))\n",
    "    w_cutout = int(sqrt(target_area / aspect_ratio))\n",
    "    \n",
    "    # Ensure dimensions don't exceed image dimensions\n",
    "    h_cutout = min(h_cutout, h)\n",
    "    w_cutout = min(w_cutout, w)\n",
    "    \n",
    "    # Get random top-left corner\n",
    "    x0 = random_int(0, w - w_cutout)\n",
    "    y0 = random_int(0, h - h_cutout)\n",
    "    \n",
    "    # Create slicing indices\n",
    "    y_slice = slice(y0, y0 + h_cutout)\n",
    "    x_slice = slice(x0, x0 + w_cutout)\n",
    "    \n",
    "    # Fill the region with the specified value\n",
    "    if v == 'random':\n",
    "        for ch in range(c):\n",
    "            output[ch, y_slice, x_slice] = random_uniform(0, 255, size=(h_cutout, w_cutout))\n",
    "    elif v == 'mean':\n",
    "        for ch in range(c):\n",
    "            output[ch, y_slice, x_slice] = image[ch].mean()\n",
    "    else:  # Default: fill with zero or specified value\n",
    "        output[:, y_slice, x_slice] = v\n",
    "    \n",
    "    return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continue ...\n",
    "\n",
    "## Mixup\n",
    "\n",
    "### Definition\n",
    "Mixup is a data augmentation technique that creates virtual training examples by linearly interpolating both inputs and labels of randomly sampled pairs of examples.\n",
    "\n",
    "### Mathematical Formulation\n",
    "Given two input-label pairs $(x_i, y_i)$ and $(x_j, y_j)$, Mixup generates a new virtual sample $(\\tilde{x}, \\tilde{y})$:\n",
    "\n",
    "$$\\tilde{x} = \\lambda x_i + (1 - \\lambda) x_j$$\n",
    "$$\\tilde{y} = \\lambda y_i + (1 - \\lambda) y_j$$\n",
    "\n",
    "where $\\lambda \\in [0, 1]$ is sampled from a Beta distribution $\\text{Beta}(\\alpha, \\alpha)$ with $\\alpha$ as a hyperparameter controlling the strength of interpolation.\n",
    "\n",
    "### Algorithm\n",
    "```python\n",
    "def mixup(batch_x, batch_y, alpha=1.0):\n",
    "    '''\n",
    "    batch_x: Input images with shape (batch_size, channels, height, width)\n",
    "    batch_y: One-hot encoded labels\n",
    "    alpha: Parameter for Beta distribution\n",
    "    '''\n",
    "    batch_size = len(batch_x)\n",
    "    \n",
    "    # Sample mixing parameter lambda\n",
    "    lam = np.random.beta(alpha, alpha, batch_size)\n",
    "    lam = np.max(lam, 1-lam)  # Ensure lambda >= 0.5 for better stability\n",
    "    lam = lam.reshape(-1, 1, 1, 1)  # Shape for broadcasting\n",
    "    \n",
    "    # Generate random indices for pairs\n",
    "    indices = np.random.permutation(batch_size)\n",
    "    \n",
    "    # Create mixed inputs and targets\n",
    "    mixed_x = lam * batch_x + (1 - lam) * batch_x[indices]\n",
    "    mixed_y = lam.reshape(-1, 1) * batch_y + (1 - lam).reshape(-1, 1) * batch_y[indices]\n",
    "    \n",
    "    return mixed_x, mixed_y\n",
    "```\n",
    "\n",
    "### Properties\n",
    "- Encourages linear behavior between training examples\n",
    "- Reduces memorization of corrupt or noisy labels\n",
    "- Improves robustness to adversarial examples\n",
    "- Acts as a form of regularization by constraining the network to behave linearly between training samples\n",
    "\n",
    "## CutMix\n",
    "\n",
    "### Definition\n",
    "CutMix is an augmentation strategy that replaces a rectangular region of an image with a patch from another image while mixing the labels proportionally to the area of the replaced region.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For two input-label pairs $(x_A, y_A)$ and $(x_B, y_B)$:\n",
    "\n",
    "$$\\tilde{x} = \\mathbf{M} \\odot x_A + (1 - \\mathbf{M}) \\odot x_B$$\n",
    "$$\\tilde{y} = \\lambda y_A + (1 - \\lambda) y_B$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{M} \\in \\{0, 1\\}^{C \\times H \\times W}$ is a binary mask with 1s for regions from image A and 0s for regions from image B\n",
    "- $\\odot$ represents element-wise multiplication\n",
    "- $\\lambda$ is the ratio of the remaining area of image A to the total image area, calculated as $\\lambda = \\frac{|\\mathbf{M}|}{C \\times H \\times W}$\n",
    "- $|\\mathbf{M}|$ is the number of ones in the mask\n",
    "\n",
    "### Algorithm\n",
    "```python\n",
    "def cutmix(batch_x, batch_y, alpha=1.0):\n",
    "    '''\n",
    "    batch_x: Input images with shape (batch_size, channels, height, width)\n",
    "    batch_y: One-hot encoded labels\n",
    "    alpha: Parameter for Beta distribution controlling box size\n",
    "    '''\n",
    "    batch_size, c, h, w = batch_x.shape\n",
    "    \n",
    "    # Sample mixing parameter lambda from Beta distribution\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    \n",
    "    # Generate random indices for pairs\n",
    "    indices = np.random.permutation(batch_size)\n",
    "    \n",
    "    # Get random box coordinates\n",
    "    cut_ratio = np.sqrt(1.0 - lam)\n",
    "    cut_w = int(w * cut_ratio)\n",
    "    cut_h = int(h * cut_ratio)\n",
    "    \n",
    "    cx = np.random.randint(w)  # Center x of cut box\n",
    "    cy = np.random.randint(h)  # Center y of cut box\n",
    "    \n",
    "    # Determine box boundaries\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, w)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, h)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, w)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, h)\n",
    "    \n",
    "    # Create new mixed images\n",
    "    mixed_x = batch_x.copy()\n",
    "    mixed_x[:, :, bby1:bby2, bbx1:bbx2] = batch_x[indices, :, bby1:bby2, bbx1:bbx2]\n",
    "    \n",
    "    # Adjust lambda based on actual box size\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (w * h))\n",
    "    \n",
    "    # Create mixed labels\n",
    "    mixed_y = lam * batch_y + (1 - lam) * batch_y[indices]\n",
    "    \n",
    "    return mixed_x, mixed_y\n",
    "```\n",
    "\n",
    "### Properties\n",
    "- Preserves more local information than Mixup\n",
    "- Introduces stronger regularization by removing portions of informative regions\n",
    "- Attends to both foreground and background contexts\n",
    "- Helps models focus on less discriminative parts of objects\n",
    "\n",
    "## Color Jittering\n",
    "\n",
    "### Definition\n",
    "Color jittering is an augmentation technique that randomly alters color properties of images, modifying brightness, contrast, saturation, and hue.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For an input image $x$ with shape $(C, H, W)$, color jittering applies the following sequential transformations:\n",
    "\n",
    "1. Brightness: $x' = x \\cdot (1 + \\delta_b)$ where $\\delta_b \\sim \\mathcal{U}(-b, b)$\n",
    "2. Contrast: $x'' = (x' - \\mu) \\cdot (1 + \\delta_c) + \\mu$ where $\\delta_c \\sim \\mathcal{U}(-c, c)$ and $\\mu$ is the mean pixel value\n",
    "3. Saturation: Converted to HSV color space, then $S_{new} = S \\cdot (1 + \\delta_s)$ where $\\delta_s \\sim \\mathcal{U}(-s, s)$\n",
    "4. Hue: Converted to HSV color space, then $H_{new} = (H + \\delta_h) \\mod 1$ where $\\delta_h \\sim \\mathcal{U}(-h, h)$\n",
    "\n",
    "The parameters $b, c, s, h$ control the strength of each transformation.\n",
    "\n",
    "### Algorithm\n",
    "```python\n",
    "def color_jittering(image, brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1):\n",
    "    '''\n",
    "    image: Input image with shape (channels, height, width)\n",
    "    brightness, contrast, saturation, hue: Maximum perturbation strengths\n",
    "    '''\n",
    "    # Apply transformations in random order\n",
    "    transforms = []\n",
    "    \n",
    "    # Brightness adjustment\n",
    "    if brightness > 0:\n",
    "        brightness_factor = random.uniform(max(0, 1-brightness), 1+brightness)\n",
    "        transforms.append(lambda img: adjust_brightness(img, brightness_factor))\n",
    "    \n",
    "    # Contrast adjustment\n",
    "    if contrast > 0:\n",
    "        contrast_factor = random.uniform(max(0, 1-contrast), 1+contrast)\n",
    "        transforms.append(lambda img: adjust_contrast(img, contrast_factor))\n",
    "    \n",
    "    # Saturation adjustment\n",
    "    if saturation > 0:\n",
    "        saturation_factor = random.uniform(max(0, 1-saturation), 1+saturation)\n",
    "        transforms.append(lambda img: adjust_saturation(img, saturation_factor))\n",
    "    \n",
    "    # Hue adjustment\n",
    "    if hue > 0:\n",
    "        hue_factor = random.uniform(-hue, hue)\n",
    "        transforms.append(lambda img: adjust_hue(img, hue_factor))\n",
    "    \n",
    "    # Shuffle transform order\n",
    "    random.shuffle(transforms)\n",
    "    \n",
    "    # Apply transforms sequentially\n",
    "    result = image.copy()\n",
    "    for transform in transforms:\n",
    "        result = transform(result)\n",
    "    \n",
    "    return result\n",
    "```\n",
    "\n",
    "### Properties\n",
    "- Increases robustness to lighting and color variations\n",
    "- Simulates different camera sensors, lighting conditions, and processing pipelines\n",
    "- Reduces model dependency on specific color patterns\n",
    "- Particularly effective for outdoor scenes and varying illumination conditions\n",
    "\n",
    "## Channel Shuffling\n",
    "\n",
    "### Definition\n",
    "Channel shuffling randomly permutes the color channels of an image, creating variations in color representation while preserving spatial information.\n",
    "\n",
    "### Mathematical Formulation\n",
    "For an RGB image $x \\in \\mathbb{R}^{3 \\times H \\times W}$ with channels $[x_R, x_G, x_B]$, channel shuffling applies a random permutation $\\sigma$ of the set $\\{0, 1, 2\\}$:\n",
    "\n",
    "$$\\tilde{x} = [x_{\\sigma(0)}, x_{\\sigma(1)}, x_{\\sigma(2)}]$$\n",
    "\n",
    "For images with more than 3 channels, this generalizes to permuting any subset of channels.\n",
    "\n",
    "### Algorithm\n",
    "```python\n",
    "def channel_shuffling(image):\n",
    "    '''\n",
    "    image: Input image with shape (channels, height, width)\n",
    "    '''\n",
    "    c, h, w = image.shape\n",
    "    \n",
    "    # Generate random permutation of channels\n",
    "    permutation = np.random.permutation(c)\n",
    "    \n",
    "    # Apply the permutation\n",
    "    shuffled_image = image[permutation, :, :]\n",
    "    \n",
    "    return shuffled_image\n",
    "```\n",
    "\n",
    "### Properties\n",
    "- Forces the model to rely less on specific channel correlations\n",
    "- Simulates different color spaces and representations\n",
    "- Prevents overfitting to specific color channel patterns\n",
    "- Particularly useful for RGB images but can be applied to any multi-channel data\n",
    "\n",
    "## Grid Distortion\n",
    "\n",
    "### Definition\n",
    "Grid distortion is a spatial augmentation technique that applies local elastic deformations to images by perturbing a regular grid of control points and using interpolation to compute the new pixel locations.\n",
    "\n",
    "### Mathematical Formulation\n",
    "1. Create a regular grid of points $G = \\{(i,j) | i=0,1,...,n; j=0,1,...,m\\}$ over the image\n",
    "2. Perturb each point with random offsets:\n",
    "   $$G'_{i,j} = (i+\\delta_{i,j}^x, j+\\delta_{i,j}^y)$$\n",
    "   where $\\delta_{i,j}^x, \\delta_{i,j}^y \\sim \\mathcal{U}(-\\Delta, \\Delta)$ with $\\Delta$ controlling distortion magnitude\n",
    "3. For each pixel $(x,y)$ in the output image, find its location in the input image:\n",
    "   $$(x', y') = \\mathcal{I}(x, y, G, G')$$\n",
    "   where $\\mathcal{I}$ is an interpolation function (bilinear, cubic, etc.)\n",
    "4. Sample the input image at position $(x', y')$ to get the output pixel value\n",
    "\n",
    "### Algorithm\n",
    "```python\n",
    "def grid_distortion(image, num_steps=5, distort_limit=0.3, interpolation='linear'):\n",
    "    '''\n",
    "    image: Input image with shape (channels, height, width)\n",
    "    num_steps: Number of grid cells in each dimension\n",
    "    distort_limit: Maximum displacement as a fraction of step size\n",
    "    interpolation: Interpolation method ('linear', 'cubic')\n",
    "    '''\n",
    "    c, h, w = image.shape\n",
    "    \n",
    "    # Create regular grid\n",
    "    x_steps = np.linspace(0, w-1, num_steps)\n",
    "    y_steps = np.linspace(0, h-1, num_steps)\n",
    "    x_grid, y_grid = np.meshgrid(x_steps, y_steps)\n",
    "    \n",
    "    # Create random displacement field\n",
    "    dx = np.random.uniform(-distort_limit, distort_limit, size=(num_steps, num_steps)) * (w // (num_steps-1))\n",
    "    dy = np.random.uniform(-distort_limit, distort_limit, size=(num_steps, num_steps)) * (h // (num_steps-1))\n",
    "    \n",
    "    # Displace grid points\n",
    "    x_grid_distorted = x_grid + dx\n",
    "    y_grid_distorted = y_grid + dy\n",
    "    \n",
    "    # Flatten grid points for interpolation\n",
    "    src_points = np.stack([y_grid.flatten(), x_grid.flatten()], axis=-1)\n",
    "    dst_points = np.stack([y_grid_distorted.flatten(), x_grid_distorted.flatten()], axis=-1)\n",
    "    \n",
    "    # Generate pixel mapping function using specified interpolation\n",
    "    map_func = get_mapping_function(src_points, dst_points, (h, w), interpolation)\n",
    "    \n",
    "    # Apply transformation channel by channel\n",
    "    result = np.zeros_like(image)\n",
    "    for i in range(c):\n",
    "        result[i] = map_func(image[i])\n",
    "    \n",
    "    return result\n",
    "```\n",
    "\n",
    "### Properties\n",
    "- Creates realistic local deformations that simulate object movements and camera perspective changes\n",
    "- Preserves topology of images while introducing geometric variance\n",
    "- More realistic than global affine transformations for organic objects\n",
    "- Effective for medical imaging, object recognition, and scenes with non-rigid objects\n",
    "- Helps models learn invariance to local geometric distortions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grayscale Conversion\n",
    "\n",
    "## Definition\n",
    "Grayscale conversion transforms a color image into a single-channel representation where pixel intensity represents brightness, eliminating chrominance information while preserving luminance.\n",
    "\n",
    "## Mathematical Formulation\n",
    "For an RGB image with dimensions $(C, H, W)$ where $C=3$, grayscale conversion applies a weighted sum of the RGB channels:\n",
    "\n",
    "$$Y = \\alpha_R \\cdot R + \\alpha_G \\cdot G + \\alpha_B \\cdot B$$\n",
    "\n",
    "Standard weights follow human perception sensitivity:\n",
    "$$Y = 0.299 \\cdot R + 0.587 \\cdot G + 0.114 \\cdot B$$\n",
    "\n",
    "Alternative ITU-R BT.709 standard:\n",
    "$$Y = 0.2126 \\cdot R + 0.7152 \\cdot G + 0.0722 \\cdot B$$\n",
    "\n",
    "## Implementation\n",
    "```python\n",
    "def grayscale_conversion(image):\n",
    "    \"\"\"\n",
    "    Convert RGB image to grayscale\n",
    "    Args:\n",
    "        image: numpy array of shape (C, H, W) with C=3\n",
    "    Returns:\n",
    "        grayscale_image: numpy array of shape (1, H, W)\n",
    "    \"\"\"\n",
    "    # Extract RGB channels\n",
    "    R, G, B = image[0], image[1], image[2]\n",
    "    \n",
    "    # Apply weighted sum\n",
    "    gray = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    \n",
    "    # Reshape to (1, H, W)\n",
    "    return gray.reshape(1, gray.shape[0], gray.shape[1])\n",
    "```\n",
    "\n",
    "# Normalization\n",
    "\n",
    "## Definition\n",
    "Normalization standardizes pixel intensity values to a specified range, improving model convergence and performance by eliminating dataset biases.\n",
    "\n",
    "## Mathematical Formulations\n",
    "\n",
    "### Min-Max Normalization\n",
    "Scales values to range $[a, b]$ (typically $[0, 1]$):\n",
    "\n",
    "$$X_{norm} = a + \\frac{(X - X_{min})(b - a)}{X_{max} - X_{min}}$$\n",
    "\n",
    "### Z-Score Normalization\n",
    "Transforms values to have zero mean and unit variance:\n",
    "\n",
    "$$X_{norm} = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "Where $\\mu$ is mean and $\\sigma$ is standard deviation.\n",
    "\n",
    "### Channel-wise Normalization\n",
    "For RGB images, typically applied per channel using mean ($\\mu_c$) and standard deviation ($\\sigma_c$):\n",
    "\n",
    "$$X_{norm}(c,h,w) = \\frac{X(c,h,w) - \\mu_c}{\\sigma_c}$$\n",
    "\n",
    "## Implementation\n",
    "```python\n",
    "def normalize_minmax(image, a=0, b=1):\n",
    "    \"\"\"\n",
    "    Apply min-max normalization\n",
    "    Args:\n",
    "        image: numpy array of shape (C, H, W)\n",
    "        a, b: target range bounds\n",
    "    Returns:\n",
    "        normalized image\n",
    "    \"\"\"\n",
    "    C, H, W = image.shape\n",
    "    normalized = np.zeros_like(image, dtype=float)\n",
    "    \n",
    "    for c in range(C):\n",
    "        channel = image[c]\n",
    "        min_val = np.min(channel)\n",
    "        max_val = np.max(channel)\n",
    "        normalized[c] = a + (channel - min_val) * (b - a) / (max_val - min_val)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def normalize_zscore(image):\n",
    "    \"\"\"\n",
    "    Apply z-score normalization\n",
    "    Args:\n",
    "        image: numpy array of shape (C, H, W)\n",
    "    Returns:\n",
    "        normalized image\n",
    "    \"\"\"\n",
    "    C, H, W = image.shape\n",
    "    normalized = np.zeros_like(image, dtype=float)\n",
    "    \n",
    "    for c in range(C):\n",
    "        channel = image[c]\n",
    "        mean = np.mean(channel)\n",
    "        std = np.std(channel)\n",
    "        normalized[c] = (channel - mean) / std\n",
    "    \n",
    "    return normalized\n",
    "```\n",
    "\n",
    "# Shearing\n",
    "\n",
    "## Definition\n",
    "Shearing is an affine transformation that displaces each point in an image by a distance proportional to its distance from an axis, creating a trapezoidal distortion effect.\n",
    "\n",
    "## Mathematical Formulation\n",
    "The shearing transformation can be represented by the matrix:\n",
    "\n",
    "$$S_x = \\begin{bmatrix} 1 & s_x & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}, S_y = \\begin{bmatrix} 1 & 0 & 0 \\\\ s_y & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "For a point $(x, y)$, horizontal shearing transforms it to:\n",
    "\n",
    "$$x' = x + s_x \\cdot y$$\n",
    "$$y' = y$$\n",
    "\n",
    "Vertical shearing transforms it to:\n",
    "\n",
    "$$x' = x$$\n",
    "$$y' = s_y \\cdot x + y$$\n",
    "\n",
    "## Implementation\n",
    "```python\n",
    "def shear_image(image, shear_x=0, shear_y=0):\n",
    "    \"\"\"\n",
    "    Apply shearing transformation to image\n",
    "    Args:\n",
    "        image: numpy array of shape (C, H, W)\n",
    "        shear_x: horizontal shear factor\n",
    "        shear_y: vertical shear factor\n",
    "    Returns:\n",
    "        sheared image\n",
    "    \"\"\"\n",
    "    C, H, W = image.shape\n",
    "    result = np.zeros_like(image)\n",
    "    \n",
    "    # Create transformation matrix\n",
    "    transform_matrix = np.array([\n",
    "        [1, shear_x, 0],\n",
    "        [shear_y, 1, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # Create coordinate matrices\n",
    "    y_coords, x_coords = np.mgrid[0:H, 0:W]\n",
    "    coords = np.stack([x_coords.flatten(), y_coords.flatten(), np.ones_like(x_coords).flatten()])\n",
    "    \n",
    "    # Apply transformation\n",
    "    new_coords = np.dot(transform_matrix, coords)\n",
    "    x_new, y_new = new_coords[0].reshape(H, W), new_coords[1].reshape(H, W)\n",
    "    \n",
    "    # Interpolate values and handle out-of-bounds\n",
    "    for c in range(C):\n",
    "        for y in range(H):\n",
    "            for x in range(W):\n",
    "                src_x, src_y = x_new[y, x], y_new[y, x]\n",
    "                \n",
    "                if 0 <= src_x < W-1 and 0 <= src_y < H-1:\n",
    "                    # Bilinear interpolation\n",
    "                    x0, y0 = int(src_x), int(src_y)\n",
    "                    dx, dy = src_x - x0, src_y - y0\n",
    "                    \n",
    "                    result[c, y, x] = (1-dx)*(1-dy)*image[c, y0, x0] + \\\n",
    "                                     dx*(1-dy)*image[c, y0, x0+1] + \\\n",
    "                                     (1-dx)*dy*image[c, y0+1, x0] + \\\n",
    "                                     dx*dy*image[c, y0+1, x0+1]\n",
    "    \n",
    "    return result\n",
    "```\n",
    "\n",
    "# Solarization\n",
    "\n",
    "## Definition\n",
    "Solarization is a non-linear transformation that partially inverts image tones at specific intensity thresholds, creating a distinctive effect where shadows or highlights may appear reversed.\n",
    "\n",
    "## Mathematical Formulation\n",
    "For a pixel intensity value $p$ and threshold $t$:\n",
    "\n",
    "$$p' = \\begin{cases} \n",
    "p & \\text{if } p < t \\\\\n",
    "255 - p & \\text{if } p \\geq t\n",
    "\\end{cases}$$\n",
    "\n",
    "Alternative formulation with continuous transition:\n",
    "\n",
    "$$p' = \\begin{cases}\n",
    "p & \\text{if } p < t_1 \\\\\n",
    "(255 - p) \\cdot \\frac{p - t_1}{t_2 - t_1} + p \\cdot \\frac{t_2 - p}{t_2 - t_1} & \\text{if } t_1 \\leq p \\leq t_2 \\\\\n",
    "255 - p & \\text{if } p > t_2\n",
    "\\end{cases}$$\n",
    "\n",
    "## Implementation\n",
    "```python\n",
    "def solarize(image, threshold=128):\n",
    "    \"\"\"\n",
    "    Apply solarization effect to image\n",
    "    Args:\n",
    "        image: numpy array of shape (C, H, W)\n",
    "        threshold: intensity threshold for inversion\n",
    "    Returns:\n",
    "        solarized image\n",
    "    \"\"\"\n",
    "    result = image.copy()\n",
    "    mask = image >= threshold\n",
    "    result[mask] = 255 - result[mask]\n",
    "    return result\n",
    "\n",
    "def solarize_smooth(image, threshold_low=100, threshold_high=150):\n",
    "    \"\"\"\n",
    "    Apply smooth solarization with transition zone\n",
    "    Args:\n",
    "        image: numpy array of shape (C, H, W)\n",
    "        threshold_low: lower bound of transition\n",
    "        threshold_high: upper bound of transition\n",
    "    Returns:\n",
    "        smoothly solarized image\n",
    "    \"\"\"\n",
    "    result = image.copy()\n",
    "    \n",
    "    # No change below threshold_low\n",
    "    mask_transition = (image >= threshold_low) & (image <= threshold_high)\n",
    "    mask_invert = image > threshold_high\n",
    "    \n",
    "    # Calculate transition weights\n",
    "    weight = (image[mask_transition] - threshold_low) / (threshold_high - threshold_low)\n",
    "    \n",
    "    # Apply smooth transition\n",
    "    result[mask_transition] = (255 - image[mask_transition]) * weight + image[mask_transition] * (1 - weight)\n",
    "    \n",
    "    # Full inversion above threshold_high\n",
    "    result[mask_invert] = 255 - image[mask_invert]\n",
    "    \n",
    "    return result\n",
    "```\n",
    "\n",
    "# Posterization\n",
    "\n",
    "## Definition\n",
    "Posterization reduces the number of distinct color/intensity levels in an image, creating regions of flat color separated by abrupt transitions, simplifying the visual information.\n",
    "\n",
    "## Mathematical Formulation\n",
    "For a pixel value $p$ with bit depth $b$ (typically 8 for standard images) reduced to $n$ bits:\n",
    "\n",
    "$$p' = \\left\\lfloor \\frac{p \\times 2^n}{2^b} \\right\\rfloor \\times \\frac{2^b}{2^n}$$\n",
    "\n",
    "Simplified for 8-bit images:\n",
    "\n",
    "$$p' = \\left\\lfloor \\frac{p}{2^{8-n}} \\right\\rfloor \\times 2^{8-n}$$\n",
    "\n",
    "## Implementation\n",
    "```python\n",
    "def posterize(image, bits=2):\n",
    "    \"\"\"\n",
    "    Reduce image to fewer intensity levels\n",
    "    Args:\n",
    "        image: numpy array of shape (C, H, W) with values 0-255\n",
    "        bits: number of bits to keep (1-8)\n",
    "    Returns:\n",
    "        posterized image\n",
    "    \"\"\"\n",
    "    if bits < 1 or bits > 8:\n",
    "        raise ValueError(\"Bits must be between 1 and 8\")\n",
    "    \n",
    "    # Create bit mask and shift values\n",
    "    mask = 2**(8 - bits) - 1\n",
    "    shift = 8 - bits\n",
    "    \n",
    "    result = image.copy()\n",
    "    \n",
    "    # Zero out the lower bits and scale back\n",
    "    result = (result & ~mask) | (mask // 2)\n",
    "    \n",
    "    # Alternative implementation:\n",
    "    # result = (image // (2**shift)) * (2**shift)\n",
    "    \n",
    "    return result\n",
    "```\n",
    "\n",
    "# Mosaic Augmentation\n",
    "\n",
    "## Definition\n",
    "Mosaic augmentation combines multiple images (typically four) into a single training sample by stitching them together in a grid pattern, enriching object detection training with varied contexts and scales.\n",
    "\n",
    "## Mathematical Formulation\n",
    "For four images $I_1, I_2, I_3, I_4$ with corresponding labels, a new image $I_{mosaic}$ is created:\n",
    "\n",
    "$$I_{mosaic}(x,y) = \\begin{cases}\n",
    "I_1(x,y) & \\text{if } x < x_c \\text{ and } y < y_c \\\\\n",
    "I_2(x-(W-x_c),y) & \\text{if } x \\geq x_c \\text{ and } y < y_c \\\\\n",
    "I_3(x,y-(H-y_c)) & \\text{if } x < x_c \\text{ and } y \\geq y_c \\\\\n",
    "I_4(x-(W-x_c),y-(H-y_c)) & \\text{if } x \\geq x_c \\text{ and } y \\geq y_c\n",
    "\\end{cases}$$\n",
    "\n",
    "Where $(x_c, y_c)$ is the center point, and $W, H$ are target dimensions.\n",
    "\n",
    "## Implementation\n",
    "```python\n",
    "def mosaic_augmentation(images, labels, target_size=(640, 640)):\n",
    "    \"\"\"\n",
    "    Combine 4 images into one mosaic\n",
    "    Args:\n",
    "        images: list of 4 numpy arrays of shape (C, H, W)\n",
    "        labels: list of 4 arrays of bounding boxes [class, x, y, w, h]\n",
    "        target_size: tuple of (height, width) for output image\n",
    "    Returns:\n",
    "        mosaic_image: combined image\n",
    "        mosaic_labels: adjusted bounding boxes\n",
    "    \"\"\"\n",
    "    assert len(images) == 4, \"Mosaic requires exactly 4 images\"\n",
    "    \n",
    "    # Create output arrays\n",
    "    H, W = target_size\n",
    "    mosaic_img = np.zeros((images[0].shape[0], H, W), dtype=np.uint8)\n",
    "    mosaic_labels = []\n",
    "    \n",
    "    # Choose random center point\n",
    "    center_x = int(random.uniform(W//4, 3*W//4))\n",
    "    center_y = int(random.uniform(H//4, 3*H//4))\n",
    "    \n",
    "    # Define quadrant coordinates\n",
    "    xc, yc = center_x, center_y\n",
    "    \n",
    "    # Process each image and place in mosaic\n",
    "    for i, (img, img_labels) in enumerate(zip(images, labels)):\n",
    "        # Original dimensions\n",
    "        h, w = img.shape[1], img.shape[2]\n",
    "        \n",
    "        # Place image in proper position based on quadrant\n",
    "        if i == 0:  # top-left\n",
    "            x1a, y1a, x2a, y2a = 0, 0, xc, yc  # mosaic coordinates\n",
    "            x1b, y1b, x2b, y2b = w - xc, h - yc, w, h  # img coordinates\n",
    "        elif i == 1:  # top-right\n",
    "            x1a, y1a, x2a, y2a = xc, 0, W, yc\n",
    "            x1b, y1b, x2b, y2b = 0, h - yc, W - xc, h\n",
    "        elif i == 2:  # bottom-left\n",
    "            x1a, y1a, x2a, y2a = 0, yc, xc, H\n",
    "            x1b, y1b, x2b, y2b = w - xc, 0, w, H - yc\n",
    "        elif i == 3:  # bottom-right\n",
    "            x1a, y1a, x2a, y2a = xc, yc, W, H\n",
    "            x1b, y1b, x2b, y2b = 0, 0, W - xc, H - yc\n",
    "        \n",
    "        # Copy image segment\n",
    "        mosaic_img[:, y1a:y2a, x1a:x2a] = img[:, y1b:y2b, x1b:x2b]\n",
    "        \n",
    "        # Adjust labels (bounding boxes)\n",
    "        if len(img_labels) > 0:\n",
    "            # Extract bounding box coordinates\n",
    "            boxes = img_labels.copy()\n",
    "            \n",
    "            # Convert bounding box coordinates from [x_center, y_center, width, height]\n",
    "            # to [x1, y1, x2, y2]\n",
    "            boxes[:, 1] = boxes[:, 1] * w\n",
    "            boxes[:, 2] = boxes[:, 2] * h\n",
    "            boxes[:, 3] = boxes[:, 3] * w\n",
    "            boxes[:, 4] = boxes[:, 4] * h\n",
    "            \n",
    "            # Convert to corners\n",
    "            boxes_corners = np.zeros_like(boxes)\n",
    "            boxes_corners[:, 0] = boxes[:, 0]  # class\n",
    "            boxes_corners[:, 1] = boxes[:, 1] - boxes[:, 3]/2  # x1\n",
    "            boxes_corners[:, 2] = boxes[:, 2] - boxes[:, 4]/2  # y1\n",
    "            boxes_corners[:, 3] = boxes[:, 1] + boxes[:, 3]/2  # x2\n",
    "            boxes_corners[:, 4] = boxes[:, 2] + boxes[:, 4]/2  # y2\n",
    "            \n",
    "            # Adjust coordinates based on placement\n",
    "            if i == 0:  # top-left\n",
    "                boxes_corners[:, 1:5] = boxes_corners[:, 1:5] - np.array([w - xc, h - yc, w - xc, h - yc])\n",
    "            elif i == 1:  # top-right\n",
    "                boxes_corners[:, 1:5] = boxes_corners[:, 1:5] + np.array([xc, -h + yc, xc, -h + yc])\n",
    "            elif i == 2:  # bottom-left\n",
    "                boxes_corners[:, 1:5] = boxes_corners[:, 1:5] + np.array([-w + xc, yc, -w + xc, yc])\n",
    "            elif i == 3:  # bottom-right\n",
    "                boxes_corners[:, 1:5] = boxes_corners[:, 1:5] + np.array([xc, yc, xc, yc])\n",
    "            \n",
    "            # Filter out boxes that are outside the mosaic\n",
    "            valid_indices = np.all(\n",
    "                np.array([\n",
    "                    boxes_corners[:, 1] < W,\n",
    "                    boxes_corners[:, 2] < H,\n",
    "                    boxes_corners[:, 3] > 0,\n",
    "                    boxes_corners[:, 4] > 0\n",
    "                ]),\n",
    "                axis=0\n",
    "            )\n",
    "            \n",
    "            # Add valid boxes to mosaic labels\n",
    "            if np.any(valid_indices):\n",
    "                # Convert back to [class, x_center, y_center, width, height] format\n",
    "                valid_boxes = boxes_corners[valid_indices]\n",
    "                valid_boxes_formatted = np.zeros_like(valid_boxes)\n",
    "                valid_boxes_formatted[:, 0] = valid_boxes[:, 0]  # class\n",
    "                valid_boxes_formatted[:, 1] = (valid_boxes[:, 1] + valid_boxes[:, 3]) / 2  # x_center\n",
    "                valid_boxes_formatted[:, 2] = (valid_boxes[:, 2] + valid_boxes[:, 4]) / 2  # y_center\n",
    "                valid_boxes_formatted[:, 3] = valid_boxes[:, 3] - valid_boxes[:, 1]  # width\n",
    "                valid_boxes_formatted[:, 4] = valid_boxes[:, 4] - valid_boxes[:, 2]  # height\n",
    "                \n",
    "                # Normalize by mosaic dimensions\n",
    "                valid_boxes_formatted[:, 1] /= W\n",
    "                valid_boxes_formatted[:, 2] /= H\n",
    "                valid_boxes_formatted[:, 3] /= W\n",
    "                valid_boxes_formatted[:, 4] /= H\n",
    "                \n",
    "                mosaic_labels.append(valid_boxes_formatted)\n",
    "    \n",
    "    # Combine all valid labels\n",
    "    if len(mosaic_labels) > 0:\n",
    "        mosaic_labels = np.vstack(mosaic_labels)\n",
    "    else:\n",
    "        mosaic_labels = np.zeros((0, 5))\n",
    "    \n",
    "    return mosaic_img, mosaic_labels\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridMask\n",
    "\n",
    "## Definition\n",
    "GridMask is a structured occlusion-based data augmentation technique that systematically removes information from images by applying a grid-like binary mask. Unlike random dropout methods, GridMask preserves spatial structure correlation by enforcing a regular pattern of occlusions, improving model robustness and generalization.\n",
    "\n",
    "## Mathematical Formulation\n",
    "\n",
    "For an input image $X \\in \\mathbb{R}^{C \\times H \\times W}$, the GridMask augmentation applies a binary mask $M \\in \\{0,1\\}^{H \\times W}$ to produce an augmented image:\n",
    "\n",
    "$$X' = X \\odot M$$\n",
    "\n",
    "where $\\odot$ represents element-wise multiplication applied channel-wise.\n",
    "\n",
    "The mask $M$ is defined by grid parameters:\n",
    "\n",
    "$$M(i,j) = \n",
    "\\begin{cases} \n",
    "0, & \\text{if } i \\bmod (d+r) \\in [0,d-1] \\text{ and } j \\bmod (d+r) \\in [0,d-1] \\\\\n",
    "1, & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "Where:\n",
    "- $d$ is the size of each deleted square region\n",
    "- $r$ is the size of each kept square region\n",
    "- $(d+r)$ defines the periodicity of the grid\n",
    "\n",
    "The effective keep ratio $\\alpha$ is controlled by:\n",
    "\n",
    "$$\\alpha = 1 - \\frac{d^2}{(d+r)^2}$$\n",
    "\n",
    "## RandomGridMask Implementation\n",
    "```python\n",
    "def gridmask(image, d_ratio=0.5, ratio=0.6, rotate=1):\n",
    "    \"\"\"\n",
    "    Apply GridMask augmentation to an image\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array of shape (C, H, W)\n",
    "        d_ratio: ratio of hole size to grid size, controls the occlusion severity\n",
    "        ratio: mask ratio, controls the overall area being masked \n",
    "        rotate: rotation angle in radians (randomized if >0)\n",
    "        \n",
    "    Returns:\n",
    "        Augmented image with GridMask applied\n",
    "    \"\"\"\n",
    "    C, H, W = image.shape\n",
    "    \n",
    "    # Calculate grid parameters\n",
    "    h, w = H, W\n",
    "    \n",
    "    # Calculate d (hole size) based on image dimensions and d_ratio\n",
    "    d = int(min(h, w) * d_ratio * ratio)\n",
    "    \n",
    "    # Grid spacing (hole + kept region)\n",
    "    grid_size = int(d / ratio)\n",
    "    \n",
    "    # Create meshgrid for coordinates\n",
    "    x, y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    \n",
    "    # Random rotation if specified\n",
    "    if rotate:\n",
    "        angle = np.random.uniform(0, rotate)\n",
    "        cos_theta = np.cos(angle)\n",
    "        sin_theta = np.sin(angle)\n",
    "        \n",
    "        # Calculate rotation center\n",
    "        center_x, center_y = w // 2, h // 2\n",
    "        \n",
    "        # Translate coordinates to origin, rotate, and translate back\n",
    "        x_orig, y_orig = x.copy(), y.copy()\n",
    "        x = (x_orig - center_x) * cos_theta - (y_orig - center_y) * sin_theta + center_x\n",
    "        y = (x_orig - center_x) * sin_theta + (y_orig - center_y) * cos_theta + center_y\n",
    "    \n",
    "    # Compute mask based on grid parameters\n",
    "    mask = (x % grid_size < (grid_size - d)) | (y % grid_size < (grid_size - d))\n",
    "    \n",
    "    # Expand mask to match image dimensions\n",
    "    mask = np.expand_dims(mask, axis=0).repeat(C, axis=0)\n",
    "    \n",
    "    # Apply mask to image\n",
    "    masked_image = image * mask\n",
    "    \n",
    "    return masked_image\n",
    "```\n",
    "\n",
    "## Advanced Parameters and Implementation\n",
    "\n",
    "### Adaptive GridMask\n",
    "The grid size and hole size can be adapted based on training progress:\n",
    "\n",
    "$$d(t) = d_{min} + \\frac{1}{2}(d_{max} - d_{min})(1 - \\cos(\\frac{\\pi t}{T}))$$\n",
    "\n",
    "where $t$ is the current epoch and $T$ is the total epochs.\n",
    "\n",
    "```python\n",
    "def adaptive_gridmask(image, epoch, total_epochs, d_min=0.1, d_max=0.5, ratio=0.6):\n",
    "    \"\"\"\n",
    "    Apply adaptive GridMask with parameters changing through training\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array of shape (C, H, W)\n",
    "        epoch: current training epoch\n",
    "        total_epochs: total training epochs\n",
    "        d_min: minimum hole size ratio\n",
    "        d_max: maximum hole size ratio\n",
    "        ratio: mask ratio\n",
    "        \n",
    "    Returns:\n",
    "        Augmented image with adaptive GridMask\n",
    "    \"\"\"\n",
    "    # Calculate adaptive d_ratio based on training progress\n",
    "    t = epoch / total_epochs\n",
    "    d_ratio = d_min + 0.5 * (d_max - d_min) * (1 - np.cos(np.pi * t))\n",
    "    \n",
    "    # Apply GridMask with the calculated parameters\n",
    "    return gridmask(image, d_ratio=d_ratio, ratio=ratio)\n",
    "```\n",
    "\n",
    "## Implementation Details\n",
    "\n",
    "GridMask's efficacy comes from:\n",
    "\n",
    "1. **Region-Based Information Deletion**: Removes contiguous regions preserving feature context\n",
    "2. **Structured Patterns**: Regular patterns help models learn invariances to occlusions\n",
    "3. **Parameter Scheduling**: Gradually increasing difficulty during training\n",
    "\n",
    "This approach is particularly effective for object detection and instance segmentation tasks, where it outperforms random erasing and cutout by preserving structural information.\n",
    "\n",
    "# Coarse Dropout\n",
    "\n",
    "## Definition\n",
    "Coarse Dropout is an augmentation technique that randomly masks out contiguous regions of an image rather than individual pixels, creating coherent \"holes\" of missing information. This forces models to learn robust features by inferring missing regions from surrounding context.\n",
    "\n",
    "## Mathematical Formulation\n",
    "\n",
    "For an input image $X \\in \\mathbb{R}^{C \\times H \\times W}$, a binary mask $M \\in \\{0,1\\}^{H \\times W}$ is generated with coarse patterns:\n",
    "\n",
    "$$X' = X \\odot M$$\n",
    "\n",
    "The mask $M$ is defined as:\n",
    "\n",
    "$$M(i,j) = \n",
    "\\begin{cases} \n",
    "0, & \\text{if } (i,j) \\in \\mathcal{R} \\\\\n",
    "1, & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "Where $\\mathcal{R}$ is the set of pixel coordinates belonging to randomly placed dropout regions.\n",
    "\n",
    "The probability of a region being dropped is given by:\n",
    "\n",
    "$$P(\\text{dropout region}) = p_{drop}$$\n",
    "\n",
    "## Implementation\n",
    "\n",
    "```python\n",
    "def coarse_dropout(image, p_drop=0.1, size_percent=(0.02, 0.2), per_channel=True):\n",
    "    \"\"\"\n",
    "    Apply Coarse Dropout to an image\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array of shape (C, H, W)\n",
    "        p_drop: probability of dropping a region\n",
    "        size_percent: tuple (min_size, max_size) as percentage of image dimensions\n",
    "        per_channel: whether to apply different masks per channel\n",
    "        \n",
    "    Returns:\n",
    "        Augmented image with Coarse Dropout applied\n",
    "    \"\"\"\n",
    "    C, H, W = image.shape\n",
    "    result = image.copy()\n",
    "    \n",
    "    # Calculate size range in pixels\n",
    "    min_size = int(min(H, W) * size_percent[0])\n",
    "    max_size = int(min(H, W) * size_percent[1])\n",
    "    \n",
    "    # Ensure minimum size is at least 1 pixel\n",
    "    min_size = max(1, min_size)\n",
    "    \n",
    "    # Number of potential dropout regions\n",
    "    # Higher number produces more fine-grained dropout pattern\n",
    "    n_holes = int(p_drop * H * W / (min_size * min_size))\n",
    "    \n",
    "    for c in range(C):\n",
    "        # Skip this channel randomly if not per_channel\n",
    "        if not per_channel and c > 0:\n",
    "            result[c] = result[0]  # Copy mask from first channel\n",
    "            continue\n",
    "            \n",
    "        # Generate coarse dropout mask for this channel\n",
    "        mask = np.ones((H, W), dtype=np.bool)\n",
    "        \n",
    "        for _ in range(n_holes):\n",
    "            # Random region size\n",
    "            size_h = np.random.randint(min_size, max_size)\n",
    "            size_w = np.random.randint(min_size, max_size)\n",
    "            \n",
    "            # Random position\n",
    "            y = np.random.randint(0, H - size_h)\n",
    "            x = np.random.randint(0, W - size_w)\n",
    "            \n",
    "            # Dropout probability check - some regions might not be dropped\n",
    "            if np.random.random() < p_drop:\n",
    "                mask[y:y+size_h, x:x+size_w] = False\n",
    "        \n",
    "        # Apply mask to this channel\n",
    "        result[c] *= mask\n",
    "    \n",
    "    return result\n",
    "```\n",
    "\n",
    "## Advanced Implementation\n",
    "\n",
    "### Structured Coarse Dropout\n",
    "\n",
    "A more structured approach uses superpixel segmentation to create semantically meaningful dropout regions:\n",
    "\n",
    "```python\n",
    "def structured_coarse_dropout(image, p_drop=0.1, n_segments=100):\n",
    "    \"\"\"\n",
    "    Apply Coarse Dropout based on superpixel segmentation\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array of shape (C, H, W)\n",
    "        p_drop: probability of dropping a segment\n",
    "        n_segments: number of superpixel segments\n",
    "        \n",
    "    Returns:\n",
    "        Augmented image with structured Coarse Dropout\n",
    "    \"\"\"\n",
    "    from skimage.segmentation import slic\n",
    "    \n",
    "    C, H, W = image.shape\n",
    "    result = image.copy()\n",
    "    \n",
    "    # Convert to format for segmentation [H,W,C]\n",
    "    img_for_segmentation = np.transpose(image, (1, 2, 0))\n",
    "    \n",
    "    # Perform superpixel segmentation\n",
    "    segments = slic(img_for_segmentation, n_segments=n_segments, compactness=10)\n",
    "    \n",
    "    # Get unique segment labels\n",
    "    unique_segments = np.unique(segments)\n",
    "    \n",
    "    # Create mask, initialize as all ones (keep all)\n",
    "    mask = np.ones((H, W), dtype=np.bool)\n",
    "    \n",
    "    # Randomly select segments to drop\n",
    "    n_drop = int(p_drop * len(unique_segments))\n",
    "    drop_segments = np.random.choice(unique_segments, size=n_drop, replace=False)\n",
    "    \n",
    "    # Set mask to False for selected segments\n",
    "    for seg_id in drop_segments:\n",
    "        mask[segments == seg_id] = False\n",
    "    \n",
    "    # Apply mask to all channels\n",
    "    for c in range(C):\n",
    "        result[c] *= mask\n",
    "    \n",
    "    return result\n",
    "```\n",
    "\n",
    "## Implementation Details\n",
    "\n",
    "Coarse Dropout differs from standard dropout in several key aspects:\n",
    "\n",
    "1. **Spatial Coherence**: Drops contiguous regions rather than random pixels\n",
    "2. **Regional Information Loss**: Forces models to learn context-aware features\n",
    "3. **Semantic Preservation**: When used with superpixels, can preserve semantic structures\n",
    "\n",
    "Practical considerations:\n",
    "- Smaller regions (2-5% of image size) work well for texture-level features\n",
    "- Larger regions (10-20%) help with higher-level semantic robustness\n",
    "- Optimal dropout probability (p_drop) typically ranges from 0.05 to 0.2\n",
    "\n",
    "This augmentation effectively prevents overfitting and improves performance on datasets with partial occlusions or missing regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
